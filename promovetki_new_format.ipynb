{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import xlsxwriter\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На входе\n",
    "1. Выгрузки GA (в формате CSV) - это выгрузки из GA сделанные из отчетов без семплинга, без дальнейшего переименования, \n",
    "    * пример корректного названия : '\\__offer\\__krovelnye-materialy_\\_ - month\\__number'\n",
    "        * название промоветки в имени файла отделено обратными слешами в начале и конце имени \\_\n",
    "\n",
    "2. Файл справочник(формат xlsx) - __от корректности и однородности этого файла зависит весь процесс обработки__.\n",
    "    * Переименовываем файл: info.xlsx\n",
    "    * Каждая вкладка(эксель страница) в инфо файле должна иметь уникальный path промоветки, который вытаскивается из ссылки\n",
    "    * __Одна вкладка строго соответствует одной промоветке__, без ссылок на другие листы и старых вкладок с такой же юрл\n",
    "    * Если у нас есть две вкладки с одинаковым юрл (path промоветке), скрипт сработает некорректно\n",
    "3. Кладем все файлы в отдельную папку, проверяем что нет дублей файлов\n",
    "4. Прописываем полный путь до папки в переменную path\n",
    "---\n",
    "На выходе\n",
    "* файл report.xlsx с 3 вкладками:\n",
    "    1. result_before_merge\n",
    "    2. result_after_merge\n",
    "    3. result_after_merge_by_lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заполняем путь к папке с файлами \n",
    "* путь до папки со всеми файлами, вначале и конце пути закрывающие слеши /full path to folder/\n",
    "\n",
    "__Вид пути для Windows__\n",
    "    *  'c:\\\\path\\\\folder_name\\\\'\n",
    "__Вид пути для Mac OS__\n",
    "    *  '/path/folder_name/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Указываем путь здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/peter/Desktop/promolines_november/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_files_name_and_path(path):\n",
    "    '''\n",
    "    Открываем папку и извлекаем название ветки из каждой выгрузки\n",
    "    Если файлов получено меньше, чем было - проверяем дубли в папке\n",
    "    Возвращает словарь название_промоветки : полный_путь_до_файла\n",
    "    '''\n",
    "    dict_csv = {}\n",
    "    k=0\n",
    "    for filename in glob.glob(os.path.join(path, '*.csv')):\n",
    "        k+=1\n",
    "        name_file = filename.split('_')[-2]\n",
    "        #print(k,'      ',name_file)\n",
    "        path_file = str(filename)\n",
    "        dict_csv[name_file] = path_file\n",
    "    print(f'\\nПолучено {len(dict_csv)} файлов в формате csv\\n')\n",
    "    return dict_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверить здесь, что импортировалось корректное количество файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Получено 77 файлов в формате csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dict_with_path = get_csv_files_name_and_path(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем глобал переменные с пустыми датафреймами, в них будем писать всю информацию\n",
    "result_before_merge = pd.DataFrame()\n",
    "result_after_merge = pd.DataFrame()\n",
    "result_after_merge_by_lm = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_result_files(dict_with_path=dict_with_path):\n",
    "    '''\n",
    "    Создаем пустые файлы для записи в них результатов\n",
    "    result_total (result_before_merge) - тотал для агрегатов после джойна по артикулам с файлом info\n",
    "    result_promo_other (result_after_merge) - тотал для агрегатов по каждому файлу выгрузки (без джойна)\n",
    "    result_after_merge_by_lm - расширенный файл для результатов по каждому LM коду после мержа с инфо файлом\n",
    "    '''\n",
    "    #генерируем структуру датафреймов\n",
    "    #читаем первый файл, берем колоноки, создаем структуру дф\n",
    "    temp = pd.read_csv(list(dict_with_path.items())[0][-1])\n",
    "    temp.columns = [i.lower().replace(' ','_') for i in temp]\n",
    "    generate_dict_for_df_structure = {i:[] for i in temp.columns if ((i != 'сегмент') and (i!='идентификатор_продукта'))}\n",
    "    generate_dict_for_df_structure['url_id'] = []\n",
    "    \n",
    "    global result_before_merge\n",
    "    global result_after_merge\n",
    "    global result_after_merge_by_lm\n",
    "    \n",
    "    #создаем пустые дф из словаря\n",
    "    result_before_merge = pd.DataFrame(generate_dict_for_df_structure)\n",
    "    result_after_merge = pd.DataFrame(generate_dict_for_df_structure)\n",
    "    \n",
    "    #добавляем дополнительное поле в словарь для записи lm code\n",
    "    generate_dict_for_df_structure['id'] = []\n",
    "    #создаем пустой датафрейм из словаря\n",
    "    result_after_merge_by_lm = pd.DataFrame(generate_dict_for_df_structure)\n",
    "      \n",
    "    #добавляем датафреймы в словарь и сохраняем на диск\n",
    "#     data_frames = {'result_before_merge':result_before_merge, 'result_after_merge':result_after_merge,\n",
    "#                   'result_after_merge_by_lm':result_after_merge_by_lm}\n",
    "#     for key, value in data_frames.items():\n",
    "#         writer = pd.ExcelWriter(path+key+'.xlsx', engine='xlsxwriter')\n",
    "#         (data_frames[key]).to_excel(writer, sheet_name='test', index = False)\n",
    "#         writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_result_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_files_from_folder(key, dict_with_path=dict_with_path):\n",
    "    '''\n",
    "    Читает файлы по сформированному словарю\n",
    "    '''\n",
    "    df = pd.read_csv(dict_with_path[key])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_before_merge_total(dict_with_path = dict_with_path):\n",
    "    '''\n",
    "    Считает агрегаты по каждой промоветке до мержа,\n",
    "    пишет в готовый файл\n",
    "    groupby_dictionary - формирует значения для .agg в groupby\n",
    "    '''\n",
    "    #result = pd.read_excel(path+'result_before_merge.xlsx')\n",
    "    global result_before_merge\n",
    "    for key, value in dict_with_path.items():\n",
    "        temp = pd.read_csv(value)\n",
    "        temp.columns = [i.lower().replace(' ','_') for i in temp]\n",
    "        groupby_dictionary = {i:'sum' for i in temp.columns if i not in ['идентификатор_продукта','сегмент']}\n",
    "        temp = temp.groupby('сегмент', as_index=False).agg(groupby_dictionary)\n",
    "        temp['url_id'] = key\n",
    "        temp.drop(['сегмент'], axis=1, inplace=True)\n",
    "        result_before_merge = pd.concat([temp, result_before_merge])\n",
    "#     writer = pd.ExcelWriter(path+'result_before_merge.xlsx', engine='xlsxwriter')\n",
    "#     result_before_merge.to_excel(writer, sheet_name='test', index = False)\n",
    "#     writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_result_before_merge_total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregation_and_merge(promo_df, temp, promo_name):\n",
    "    \n",
    "    #датафрейма для записи результатов после джойна\n",
    "    #total = pd.read_excel(path+'result_after_merge.xlsx')\n",
    "    #датафрейм для записи агрегатов по промоветкам без джойна\n",
    "    \n",
    "    global result_after_merge\n",
    "    global result_after_merge_by_lm\n",
    "    \n",
    "    '''\n",
    "    получает вкладку из справочника и соответствующей ей датафрейм, мержит, считает агрегаты и сохраняет в глобальные датафреймы\n",
    "    promo_df -> выгрузка из GA\n",
    "    temp -> соответствующая вкладка из инфо файла\n",
    "    '''\n",
    "    \n",
    "    #приводит column names в стандартный вид\n",
    "    promo_df.columns = [i.lower().replace(' ','_') for i in promo_df]\n",
    "    #меняем тип данных для операций\n",
    "    for i in promo_df.columns:\n",
    "        if i not in ['идентификатор_продукта','сегмент']:\n",
    "            promo_df[i] = promo_df[i].astype('float')\n",
    "    \n",
    "    #генерируем словарь название колонки:'sum'\n",
    "    groupby_dictionary = {i:'sum' for i in promo_df.columns if i not in ['идентификатор_продукта','сегмент']}\n",
    "    \n",
    "    #агрегируем данные по каждому LM коду (исключаем возможность дублирования LM кодов в выгрузки) \n",
    "    promo_df = promo_df.groupby('идентификатор_продукта', as_index=False).agg(groupby_dictionary).\\\n",
    "                                                        rename(columns={'идентификатор_продукта':'id'})\n",
    "    object_values_in_id = ['not set','notset','(not set)']\n",
    "    promo_df = promo_df[~promo_df['id'].isin(object_values_in_id)]\n",
    "    promo_df['id'] = promo_df['id'].astype('int64')\n",
    "    \n",
    "    temp.drop_duplicates(subset = 'id', keep = 'first', inplace = True)\n",
    "    #мержим promo_df и temp\n",
    "    test_new = temp.merge(promo_df, on='id', how='left').fillna(0)\n",
    "    \n",
    "    #считаем тотал по одной промоветке\n",
    "    promo_df_total_sum = test_new.groupby('url_id', as_index=False).agg(groupby_dictionary)\n",
    "\n",
    "    \n",
    "    #пишем в глобальную переменную, датафрейм result_after_merge_by_lm\n",
    "    result_after_merge_by_lm = pd.concat([test_new,result_after_merge_by_lm])\n",
    "    #и сохраняем каждый файл отдельно\n",
    "    #writer_1 = pd.ExcelWriter(path+'done_'+promo_name+'.xlsx', engine = 'xlsxwriter')\n",
    "    #test_new.to_excel(writer_1, sheet_name = 'test', index=False)\n",
    "    #writer_1.save()\n",
    "    \n",
    "    \n",
    "    #пишем в глобальную переменную result_after_merge \n",
    "    result_after_merge = pd.concat([promo_df_total_sum,result_after_merge])\n",
    "    #writer_2 = pd.ExcelWriter(path+'result_after_merge.xlsx', engine='xlsxwriter')\n",
    "    #total.to_excel(writer_2, sheet_name='test', index = False)\n",
    "    #writer_2.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_result_df():\n",
    "    '''\n",
    "    после прохождения по всем вкладкам в функции reading_info_file записываем 3 датафрейма в один xlsx файл и сохраняем\n",
    "    '''\n",
    "    global result_before_merge\n",
    "    global result_after_merge\n",
    "    global result_after_merge_by_lm\n",
    "    \n",
    "    #идем по словарю и сохраняем результирующие датафреймы в один файл на разные вкладки с именем key\n",
    "    data_frames = {'result_before_merge':result_before_merge, 'result_after_merge':result_after_merge,\n",
    "                  'result_after_merge_by_lm':result_after_merge_by_lm}\n",
    "    current_month = (datetime.datetime.now()).month\n",
    "    writer = pd.ExcelWriter(path+'report_month_'+str(current_month)+'.xlsx', engine='xlsxwriter')  \n",
    "    for key, value in data_frames.items():\n",
    "        data_frames[key] = data_frames[key].fillna(0)\n",
    "        (data_frames[key]).to_excel(writer, sheet_name=key, index = False)\n",
    "    writer.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_info_file():\n",
    "    '''\n",
    "    Обрабатывает файл справочник\n",
    "    Идет по названиям листов, сохраняет лист в дф,\n",
    "    берет значение юрл со страницы, выделяет ключ и пробует передать его в ф-ю reading_files_from_folder\n",
    "    '''\n",
    "    #флаг на ошибки\n",
    "\n",
    "    temp_path = path+'info.xlsx'\n",
    "    xls = pd.ExcelFile(temp_path)\n",
    "    list_of_sheets = [i for i in xls.sheet_names]\n",
    "    #print(list_of_sheets)\n",
    "    for i in list_of_sheets:\n",
    "        error1 = False\n",
    "        error2 = False\n",
    "        \n",
    "        #чтение датафрейма с конкретным листом\n",
    "        df = pd.read_excel(xls, sheet_name=i, header=None).iloc[:,:2]\n",
    "        #пробуем п\n",
    "        try:\n",
    "            df.columns = ['id','url_id']\n",
    "        except Exception as e:\n",
    "            print(f' {i}:Ошибка на этапе выделения ключа, проверить что на вкладке есть информация\\n')\n",
    "            error1 = True\n",
    "        \n",
    "        if error1 == False:\n",
    "            \n",
    "            if df.iloc[0,1][-1] == '/':\n",
    "                key = df.iloc[0,1].split('/')[-2]\n",
    "                df['url_id'] = key\n",
    "            else:\n",
    "                key = df.iloc[0,1].split('/')[-1]\n",
    "            try:\n",
    "                promo_df = reading_files_from_folder(key, dict_with_path=dict_with_path)\n",
    "                #display(promo_df.head())\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f'Вкладка {[i]} из info файла пропущена, не найдена соответствующая выгрузка')\n",
    "                error2 = True\n",
    "            \n",
    "            if error2 == False:\n",
    "                aggregation_and_merge(promo_df=promo_df, temp = df, promo_name=key)\n",
    "    \n",
    "    dump_result_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вкладка ['заборы калитки ворота '] из info файла пропущена, не найдена соответствующая выгрузка\n",
      "Вкладка ['инструменты для дачи'] из info файла пропущена, не найдена соответствующая выгрузка\n",
      "Вкладка ['мототехника для дачи'] из info файла пропущена, не найдена соответствующая выгрузка\n",
      "Вкладка ['Смесители дизайнерский стиль'] из info файла пропущена, не найдена соответствующая выгрузка\n",
      "Вкладка ['Смесители природный стиль'] из info файла пропущена, не найдена соответствующая выгрузка\n",
      "Вкладка ['Смесители стиль шарм'] из info файла пропущена, не найдена соответствующая выгрузка\n",
      "Вкладка ['товары для безопасн нового года'] из info файла пропущена, не найдена соответствующая выгрузка\n",
      "Вкладка ['новогодн уличн гирлянды'] из info файла пропущена, не найдена соответствующая выгрузка\n",
      "Вкладка ['гирлянды для дома'] из info файла пропущена, не найдена соответствующая выгрузка\n",
      "Вкладка ['подарки для мужчин'] из info файла пропущена, не найдена соответствующая выгрузка\n",
      "Вкладка ['необычные подарки'] из info файла пропущена, не найдена соответствующая выгрузка\n",
      " ГГР:Ошибка на этапе выделения ключа, проверить что на вкладке есть информация\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reading_info_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
